{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition ‚Äì MLOPS_INTERNSHIP_TASK 06!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Description üìÑ\n",
    "\n",
    "‚ùÑÔ∏è Create a program that perform below mentioned task upon recognizing a particular face. \n",
    "\n",
    "üìå When it recognize your face then - \n",
    "\n",
    "üëâ It send mail to your mail id by writing this is face of your_name.\n",
    "\n",
    "üëâ Second it send whatsapp message to your friend, it can be anything. \n",
    "\n",
    "üìå When it recognize second  face, it can be your friend or family members face.\n",
    "\n",
    "üëâ Create EC2 instance in the AWS using CLI. \n",
    "\n",
    "üëâ Create 5 GB EBS volume and attach it to the instance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER USER-NUMBER : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-cef4befef2f0>:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces == ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import threading\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Loading HAAR cascase classifier\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function for detecting faces\n",
    "def face_extract(img):\n",
    "    faces = classifier.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces == ():\n",
    "        return None\n",
    "    \n",
    "    # Croppping the face\n",
    "    for (x, y, width, height) in faces:\n",
    "        crop_face = img[y:y+height+10, x:x+width+10]\n",
    "        \n",
    "    return crop_face\n",
    "\n",
    "# Initialize Webcam\n",
    "user_id = input('ENTER USER-NUMBER : ')\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extract(frame) is None:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        count +=1\n",
    "        face = cv2.resize(face_extract(frame), (200,200))\n",
    "        \n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/user_' + str(user_id) + \"_\" + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        face1 = cv2.flip(face,1)\n",
    "        cv2.putText(face1, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Crop face', face1)\n",
    "        \n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTER USER-NUMBER : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ae76b75f569c>:16: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces == ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import threading\n",
    "\n",
    "# Loading HAAR cascase classifier\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function for detecting faces\n",
    "def face_extract(img):\n",
    "    faces = classifier.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces == ():\n",
    "        return None\n",
    "    \n",
    "    # Croppping the face\n",
    "    for (x, y, width, height) in faces:\n",
    "        crop_face = img[y:y+height+10, x:x+width+10]\n",
    "        \n",
    "    return crop_face\n",
    "\n",
    "# Initialize Webcam\n",
    "user_id = input('ENTER USER-NUMBER : ')\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if face_extract(frame) is None:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        count +=1\n",
    "        face = cv2.resize(face_extract(frame), (200,200))\n",
    "        \n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user2/user_' + str(user_id) + \"_\" + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        face1 = cv2.flip(face,1)\n",
    "        cv2.putText(face1, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Crop face', face1)\n",
    "        \n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    user_id=int(os.path.split(image_path)[-1].split(\"_\")[1])\n",
    "    Labels.append(user_id)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "\n",
    "#saving our created model in a file\n",
    "model.save('ModelFiles/model.yml')\n",
    "print(\"Model trained sucessefully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "# Get the training data we previously made\n",
    "data_path = './faces/user2/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    user_id=int(os.path.split(image_path)[-1].split(\"_\")[1])\n",
    "    Labels.append(user_id)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "\n",
    "#saving our created model in a file\n",
    "model.save('ModelFiles/model2.yml')\n",
    "print(\"Model 2 trained sucessefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-1924320c1152>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhargava.... check your email and also a whatsapp message is sent\n",
      "13\n",
      "04\n",
      "In 14 seconds web.whatsapp.com will open and after 20 seconds message will be delivered\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "user_id=0\n",
    "name = \"\"\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "model1 = cv2.face_LBPHFaceRecognizer.create();\n",
    "model1.read('ModelFiles/model.yml')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    image1, face1 = face_detector(frame)\n",
    "    cv2.putText(image1, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "    cv2.imshow('Face Recognition', image1 )\n",
    "    \n",
    "    try:\n",
    "        face1 = cv2.cvtColor(face1, cv2.COLOR_BGR2GRAY)\n",
    "        results1 = model1.predict(face1)\n",
    "        user_id1 = results1[0]\n",
    "        score1 = results1[1]\n",
    "\n",
    "        if score1 < 500:\n",
    "            confidence1 = int( 100 * (1 - (score1)/400) )\n",
    "            if confidence1 > 85:\n",
    "                cv2.imshow('Face Recognition', image1 )\n",
    "                display_string = str(confidence1) + '% Confident it is bhargava'\n",
    "                cv2.putText(image1,display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,255), 2)\n",
    "                print(\"Bhargava.... check your email and also a whatsapp message is sent\")\n",
    "                %run ./sending_message.ipynb\n",
    "                break           \n",
    "        else:\n",
    "            print(\"Unknown user found\")\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image1, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-6-e7f74144bfad>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are shahid so Check your AWS\n",
      "\t\t\t Success : Instance Launched\n",
      "\t\t\t Success : Volume Created\n",
      "\t\t\t Success : Volume ATTACHED\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "user_id=0\n",
    "name = \"\"\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "model2 = cv2.face_LBPHFaceRecognizer.create();\n",
    "model2.read('ModelFiles/model2.yml')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read() \n",
    "    image2, face2 = face_detector(frame)\n",
    "    cv2.putText(image2, \"looking for right face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "    cv2.imshow('Face Recognition', image2 )\n",
    "    \n",
    "    try:\n",
    "        face2 = cv2.cvtColor(face2, cv2.COLOR_BGR2GRAY)\n",
    "        results2 = model2.predict(face2)\n",
    "        user_id2 = results2[0]\n",
    "        score2 = results2[1]\n",
    "\n",
    "        if score2 < 500:\n",
    "            confidence2= int( 100 * (1 - (score2)/400) )\n",
    "            if confidence2 > 85:\n",
    "                cv2.imshow('Face Recognition', image2 )\n",
    "                display_string = str(confidence2) + '% Confident it is shahid'\n",
    "                cv2.putText(image2, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,255), 2)\n",
    "                print(\"You are shahid so Check your AWS\")\n",
    "                os.system(\"aws ec2 create-key-pair  --key-name mlopskey\")\n",
    "                a = os.system(\"aws ec2 run-instances  --image-id ami-0d8d212151031f51c  --count 1  --instance-type t2.micro --key-name mlopskey  --subnet-id subnet-42f6810e   --tag-specifications  ResourceType=instance,Tags=[{Key=Name,Value=mlopstask6}]\")\n",
    "                if a == 0:\n",
    "                    print(\"\\t\\t\\t Success : Instance Launched\")\n",
    "                b = os.system(\"aws ec2 create-volume --volume-type gp2 --size 5 --availability-zone us-east-2c  --tag-specifications  ResourceType=volume,Tags=[{Key=Name,Value=mlopstask6}]\")\n",
    "                if b == 0:\n",
    "                    print(\"\\t\\t\\t Success : Volume Created\")\n",
    "\n",
    "                time.sleep(30)\n",
    "                ins_id = subprocess.getoutput(\"aws ec2 describe-instances --filters Name=tag:Name,Values=mlopstask6 --query Reservations[*].Instances[*].[InstanceId] --output text\")\n",
    "                vol_id = subprocess.getoutput(\"aws ec2 describe-volumes  --filters Name=tag:Name,Values=mlopstask6* --query Volumes[*].[VolumeId] --output text\")\n",
    "                c = os.system(\"aws ec2 attach-volume --instance-id {} --volume-id {} --device /dev/sdf\".format(ins_id,vol_id))\n",
    "                if c == 0:\n",
    "                    print(\"\\t\\t\\t Success : Volume ATTACHED\")\n",
    "                break\n",
    "            \n",
    "        else:\n",
    "            print(\"Unknown user found\")\n",
    "            cv2.imshow('Face Recognition', image2 )\n",
    "            display_string = str(confidence2) + '% Confident it is not shahid'\n",
    "            cv2.putText(image2, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,0), 2)\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image2, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
